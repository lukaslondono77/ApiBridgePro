# OpenAI API Connector
# 
# Setup:
#   1. Get API key from https://platform.openai.com/api-keys
#   2. export OPENAI_API_KEY=sk-...
#   3. Add this to your connectors.yaml
# 
# Usage:
#   curl -X POST http://localhost:8000/proxy/openai/chat/completions \
#     -H "Content-Type: application/json" \
#     -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"Hello!"}]}'
# 
# Rate Limits:
#   Free tier: 3 RPM, 40,000 TPM
#   Tier 1: 3,500 RPM, 90,000 TPM
#   Tier 2: 3,500 RPM, 160,000 TPM
# 
# Cost:
#   gpt-3.5-turbo: $0.0005/1K tokens (input), $0.0015/1K tokens (output)
#   gpt-4: $0.03/1K tokens (input), $0.06/1K tokens (output)

openai:
  base_url: https://api.openai.com/v1
  
  auth:
    type: bearer
    token: ${OPENAI_API_KEY}
  
  allow_paths:
    - "^/chat/completions$"
    - "^/completions$"
    - "^/embeddings$"
    - "^/models$"
    - "^/models/.*$"
  
  rate_limit:
    capacity: 3500  # Tier 1 RPM limit
    refill_per_sec: 58  # 3500/60
  
  cache_ttl_seconds: 0  # Don't cache AI responses (non-deterministic)
  
  strategy:
    timeout_ms: 60000  # 60 seconds for long completions
    retries: 2
  
  budget:
    monthly_usd_max: 100  # Adjust based on your needs
    on_exceed: block
  
  cost_per_call_usd: 0.002  # Rough estimate for average request
  
  # Optional: Redact prompts/responses in logs
  pii_protection:
    enabled: false  # Enable if prompts contain PII
    auto_scan: true
    action: redact
  
  passthrough_headers:
    - "content-type"
    - "openai-organization"
    - "openai-processing-ms"

